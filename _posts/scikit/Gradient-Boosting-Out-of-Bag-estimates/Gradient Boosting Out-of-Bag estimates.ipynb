{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out-of-bag (OOB) estimates can be a useful heuristic to estimate the “optimal” number of boosting iterations. OOB estimates are almost identical to cross-validation estimates but they can be computed on-the-fly without the need for repeated model fitting. OOB estimates are only available for Stochastic Gradient Boosting (i.e. subsample < 1.0), the estimates are derived from the improvement in loss based on the examples not included in the bootstrap sample (the so-called out-of-bag examples). The OOB estimator is a pessimistic estimator of the true test loss, but remains a fairly good approximation for a small number of trees.\n",
    "\n",
    "The figure shows the cumulative sum of the negative OOB improvements as a function of the boosting iteration. As you can see, it tracks the test loss for the first hundred iterations but then diverges in a pessimistic way. The figure also shows the performance of 3-fold cross validation which usually gives a better estimate of the test loss but is computationally more demanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New to Plotly?\n",
    "Plotly's Python library is free and open source! [Get started](https://plot.ly/python/getting-started/) by downloading the client and [reading the primer](https://plot.ly/python/getting-started/).\n",
    "<br>You can set up Plotly to work in [online](https://plot.ly/python/getting-started/#initialization-for-online-plotting) or [offline](https://plot.ly/python/getting-started/#initialization-for-offline-plotting) mode, or in [jupyter notebooks](https://plot.ly/python/getting-started/#start-plotting-online).\n",
    "<br>We also have a quick-reference [cheatsheet](https://images.plot.ly/plotly-documentation/images/python_cheat_sheet.pdf) (new!) to help you get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial imports [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold) and [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6840\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate data (adapted from G. Ridgeway's gbm example)\n",
    "n_samples = 1000\n",
    "random_state = np.random.RandomState(13)\n",
    "x1 = random_state.uniform(size=n_samples)\n",
    "x2 = random_state.uniform(size=n_samples)\n",
    "x3 = random_state.randint(0, 4, size=n_samples)\n",
    "\n",
    "p = 1 / (1.0 + np.exp(-(np.sin(3 * x1) - 4 * x2 + x3)))\n",
    "y = random_state.binomial(1, p, size=n_samples)\n",
    "\n",
    "X = np.c_[x1, x2, x3]\n",
    "\n",
    "X = X.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,\n",
    "                                                    random_state=9)\n",
    "\n",
    "# Fit classifier with out-of-bag estimates\n",
    "params = {'n_estimators': 1200, 'max_depth': 3, 'subsample': 0.5,\n",
    "          'learning_rate': 0.01, 'min_samples_leaf': 1, 'random_state': 3}\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "acc = clf.score(X_test, y_test)\n",
    "print(\"Accuracy: {:.4f}\".format(acc))\n",
    "\n",
    "n_estimators = params['n_estimators']\n",
    "x = np.arange(n_estimators) + 1\n",
    "\n",
    "\n",
    "def heldout_score(clf, X_test, y_test):\n",
    "    \"\"\"compute deviance scores on ``X_test`` and ``y_test``. \"\"\"\n",
    "    score = np.zeros((n_estimators,), dtype=np.float64)\n",
    "    for i, y_pred in enumerate(clf.staged_decision_function(X_test)):\n",
    "        score[i] = clf.loss_(y_test, y_pred)\n",
    "    return score\n",
    "\n",
    "\n",
    "def cv_estimate(n_splits=3):\n",
    "    cv = KFold(n_splits=n_splits)\n",
    "    cv_clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    val_scores = np.zeros((n_estimators,), dtype=np.float64)\n",
    "    for train, test in cv.split(X_train, y_train):\n",
    "        cv_clf.fit(X_train[train], y_train[train])\n",
    "        val_scores += heldout_score(cv_clf, X_train[test], y_train[test])\n",
    "    val_scores /= n_splits\n",
    "    return val_scores\n",
    "\n",
    "\n",
    "# Estimate best n_estimator using cross-validation\n",
    "cv_score = cv_estimate(3)\n",
    "\n",
    "# Compute best n_estimator for test data\n",
    "test_score = heldout_score(clf, X_test, y_test)\n",
    "\n",
    "# negative cumulative sum of oob improvements\n",
    "cumsum = -np.cumsum(clf.oob_improvement_)\n",
    "\n",
    "# min loss according to OOB\n",
    "oob_best_iter = x[np.argmin(cumsum)]\n",
    "\n",
    "# min loss according to test (normalize such that first loss is 0)\n",
    "test_score -= test_score[0]\n",
    "test_best_iter = x[np.argmin(test_score)]\n",
    "\n",
    "# min loss according to cv (normalize such that first loss is 0)\n",
    "cv_score -= cv_score[0]\n",
    "cv_best_iter = x[np.argmin(cv_score)]\n",
    "\n",
    "# color brew for the three curves\n",
    "oob_color = 'purple'\n",
    "test_color = 'green'\n",
    "cv_color = 'orange'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1 = go.Scatter(x=x, y=cumsum, \n",
    "                name='OOB loss', \n",
    "                mode='lines',\n",
    "                line=dict(color=oob_color, width=1)\n",
    "                )\n",
    "\n",
    "p2 = go.Scatter(x=x, y=test_score, \n",
    "                name='Test loss', \n",
    "                mode='lines',\n",
    "                line=dict(color=test_color, width=1)\n",
    "                )\n",
    "\n",
    "p3 = go.Scatter(x=x, y=cv_score, \n",
    "                name='CV loss',\n",
    "                mode='lines',\n",
    "                line=dict(color=cv_color, width=1 )\n",
    "                )\n",
    "\n",
    "p4 = go.Scatter(x=2 * [oob_best_iter], \n",
    "                y=[-0.3, 0.1],\n",
    "                showlegend=False,\n",
    "                mode='lines',\n",
    "                line=dict(color=oob_color, width=1)\n",
    "                )\n",
    "\n",
    "p5 = go.Scatter(x=2 * [test_best_iter],\n",
    "                y=[-0.3, 0.1],\n",
    "                showlegend=False,\n",
    "                mode='lines',\n",
    "                line=dict(color=test_color, width=1)\n",
    "                )\n",
    "\n",
    "p6 = go.Scatter(x=2 * [cv_best_iter], \n",
    "                y=[-0.3, 0.1],\n",
    "                showlegend=False,\n",
    "                mode='lines',\n",
    "                line=dict(color=cv_color, width=1)\n",
    "                )\n",
    "\n",
    "layout = go.Layout(xaxis=dict(title='number of iterations',\n",
    "                              ticktext=['0','OOB','CV','Test','400',\n",
    "                                        '600','800','1000','1200'],\n",
    "                              tickvals=[0, oob_best_iter, cv_best_iter,\n",
    "                                        test_best_iter, 400, 600, 800,\n",
    "                                        1000, 1200]),\n",
    "                  yaxis=dict(title='normalized loss'),\n",
    "                  hovermode='closest'\n",
    "                  )\n",
    "\n",
    "fig = go.Figure(data=[p1, p2, p3, p4, p5, p6 ], layout=layout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Diksha_Gabha/3127.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: \n",
    "\n",
    "        Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "\n",
    "License:\n",
    "\n",
    "        BSD 3 clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href=\"//fonts.googleapis.com/css?family=Open+Sans:600,400,300,200|Inconsolata|Ubuntu+Mono:400,700\" rel=\"stylesheet\" type=\"text/css\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"http://help.plot.ly/documentation/all_static/css/ipython-notebook-custom.css\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/plotly/publisher.git\n",
      "  Cloning https://github.com/plotly/publisher.git to /tmp/pip-DAT5WP-build\n",
      "Installing collected packages: publisher\n",
      "  Found existing installation: publisher 0.10\n",
      "    Uninstalling publisher-0.10:\n",
      "      Successfully uninstalled publisher-0.10\n",
      "  Running setup.py install for publisher ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25hSuccessfully installed publisher-0.10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML('<link href=\"//fonts.googleapis.com/css?family=Open+Sans:600,400,300,200|Inconsolata|Ubuntu+Mono:400,700\" rel=\"stylesheet\" type=\"text/css\" />'))\n",
    "display(HTML('<link rel=\"stylesheet\" type=\"text/css\" href=\"http://help.plot.ly/documentation/all_static/css/ipython-notebook-custom.css\">'))\n",
    "\n",
    "! pip install git+https://github.com/plotly/publisher.git --upgrade\n",
    "import publisher\n",
    "publisher.publish(\n",
    "    'Gradient Boosting Out-of-Bag estimates.ipynb', 'scikit-learn/plot-gradient-boosting-oob/', 'Gradient Boosting Out-of-Bag Estimates | plotly',\n",
    "    ' ',\n",
    "    title = 'Gradient Boosting Out-of-Bag Estimates | plotly',\n",
    "    name = 'Gradient Boosting Out-of-Bag Estimates ',\n",
    "    has_thumbnail='true', thumbnail='thumbnail/out-of-bag.jpg', \n",
    "    language='scikit-learn', page_type='example_index',\n",
    "    display_as='ensemble_methods', order=18,\n",
    "    ipynb= '~Diksha_Gabha/3129')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
