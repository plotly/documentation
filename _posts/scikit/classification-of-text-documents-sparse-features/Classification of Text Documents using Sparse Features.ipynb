{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example showing how scikit-learn can be used to classify documents by topics using a bag-of-words approach. This example uses a scipy.sparse matrix to store the features and demonstrates various classifiers that can efficiently handle sparse matrices.\n",
    "\n",
    "The dataset used in this example is the 20 newsgroups dataset. It will be automatically downloaded, then cached.\n",
    "\n",
    "The bar plot indicates the accuracy, training time (normalized) and test time (normalized) of each classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New to Plotly?\n",
    "Plotly's Python library is free and open source! [Get started](https://plot.ly/python/getting-started/) by downloading the client and [reading the primer](https://plot.ly/python/getting-started/).\n",
    "<br>You can set up Plotly to work in [online](https://plot.ly/python/getting-started/#initialization-for-online-plotting) or [offline](https://plot.ly/python/getting-started/#initialization-for-offline-plotting) mode, or in [jupyter notebooks](https://plot.ly/python/getting-started/#start-plotting-online).\n",
    "<br>We also have a quick-reference [cheatsheet](https://images.plot.ly/plotly-documentation/images/python_cheat_sheet.pdf) (new!) to help you get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display progress logs on stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse commandline arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: __main__.py [options]\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --report              Print a detailed classification report.\n",
      "  --chi2_select=SELECT_CHI2\n",
      "                        Select some number of features using a chi-squared\n",
      "                        test\n",
      "  --confusion_matrix    Print the confusion matrix.\n",
      "  --top10               Print ten most discriminative terms per class for\n",
      "                        every classifier.\n",
      "  --all_categories      Whether to use all categories or not.\n",
      "  --use_hashing         Use a hashing vectorizer.\n",
      "  --n_features=N_FEATURES\n",
      "                        n_features when using the hashing vectorizer.\n",
      "  --filtered            Remove newsgroup information that is easily overfit:\n",
      "                        headers, signatures, and quoting.\n"
     ]
    }
   ],
   "source": [
    "op = OptionParser()\n",
    "op.add_option(\"--report\",\n",
    "              action=\"store_true\", dest=\"print_report\",\n",
    "              help=\"Print a detailed classification report.\")\n",
    "op.add_option(\"--chi2_select\",\n",
    "              action=\"store\", type=\"int\", dest=\"select_chi2\",\n",
    "              help=\"Select some number of features using a chi-squared test\")\n",
    "op.add_option(\"--confusion_matrix\",\n",
    "              action=\"store_true\", dest=\"print_cm\",\n",
    "              help=\"Print the confusion matrix.\")\n",
    "op.add_option(\"--top10\",\n",
    "              action=\"store_true\", dest=\"print_top10\",\n",
    "              help=\"Print ten most discriminative terms per class\"\n",
    "                   \" for every classifier.\")\n",
    "op.add_option(\"--all_categories\",\n",
    "              action=\"store_true\", dest=\"all_categories\",\n",
    "              help=\"Whether to use all categories or not.\")\n",
    "op.add_option(\"--use_hashing\",\n",
    "              action=\"store_true\",\n",
    "              help=\"Use a hashing vectorizer.\")\n",
    "op.add_option(\"--n_features\",\n",
    "              action=\"store\", type=int, default=2 ** 16,\n",
    "              help=\"n_features when using the hashing vectorizer.\")\n",
    "op.add_option(\"--filtered\",\n",
    "              action=\"store_true\",\n",
    "              help=\"Remove newsgroup information that is easily overfit: \"\n",
    "                   \"headers, signatures, and quoting.\")\n",
    "\n",
    "op.print_help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Get command line arguments add\n",
    "\n",
    "    (opts, args) = op.parse_args()\n",
    "    \n",
    "and set the following as:\n",
    "\n",
    "all_categories = opts.all_categories\n",
    "\n",
    "filtered = opts.filtered\n",
    "\n",
    "use_hashing = opts.use_hashing\n",
    "\n",
    "n_features = opts.n_features\n",
    "\n",
    "select_chi2 = opts.select_chi2\n",
    "\n",
    "print_cm = opts.print_cm\n",
    "\n",
    "print_top10 = opts.print_top10\n",
    "\n",
    "print_report = opts.print_report\n",
    "\n",
    "For this tutorial we are taking these values as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_categories = True\n",
    "filtered = True\n",
    "use_hashing = True\n",
    "n_features = 2 ** 16\n",
    "select_chi2 = 10\n",
    "print_cm = True\n",
    "print_top10 = True\n",
    "print_report = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some categories from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if all_categories:\n",
    "    categories = None\n",
    "else:\n",
    "    categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "all\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "if filtered:\n",
    "    remove = ('headers', 'footers', 'quotes')\n",
    "else:\n",
    "    remove = ()\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "print('data loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order of labels in `target_names` can be different from `categories`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_names = data_train.target_names\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 13.782MB (training set)\n",
      "7532 documents - 8.262MB (test set)\n"
     ]
    }
   ],
   "source": [
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split a training set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 3.209865s at 4.294MB/s\n",
      "n_samples: 11314, n_features: 65536\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 1.774443s at 4.656MB/s\n",
      "n_samples: 7532, n_features: 65536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "if use_hashing:\n",
    "    vectorizer = HashingVectorizer(stop_words='english', non_negative=True,\n",
    "                                   n_features=n_features)\n",
    "    X_train = vectorizer.transform(data_train.data)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping from integer feature name to original token string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 10 best features by a chi-squared test\n",
      "done in 0.427792s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if use_hashing:\n",
    "    feature_names = None\n",
    "else:\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "if select_chi2:\n",
    "    print(\"Extracting %d best features by a chi-squared test\" %\n",
    "          select_chi2)\n",
    "    t0 = time()\n",
    "    ch2 = SelectKBest(chi2, k=select_chi2)\n",
    "    X_train = ch2.fit_transform(X_train, y_train)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    if feature_names:\n",
    "        # keep selected feature names\n",
    "        feature_names = [feature_names[i] for i\n",
    "                         in ch2.get_support(indices=True)]\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "\n",
    "    if print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "    if print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diksha/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/ridge.py:311: UserWarning:\n",
      "\n",
      "In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.216s\n",
      "test time:  0.001s\n",
      "accuracy:   0.186\n",
      "dimensionality: 10\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00       319\n",
      "           comp.graphics       0.00      0.00      0.00       389\n",
      " comp.os.ms-windows.misc       0.53      0.49      0.51       394\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.00      0.00      0.00       395\n",
      "            misc.forsale       0.00      0.00      0.00       390\n",
      "               rec.autos       0.69      0.34      0.45       396\n",
      "         rec.motorcycles       0.85      0.25      0.39       398\n",
      "      rec.sport.baseball       0.00      0.00      0.00       397\n",
      "        rec.sport.hockey       0.07      0.96      0.12       399\n",
      "               sci.crypt       0.67      0.41      0.50       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.00      0.00      0.00       396\n",
      "               sci.space       0.56      0.30      0.39       394\n",
      "  soc.religion.christian       0.48      0.42      0.45       398\n",
      "      talk.politics.guns       0.56      0.17      0.26       364\n",
      "   talk.politics.mideast       0.88      0.23      0.36       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "             avg / total       0.27      0.19      0.18      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[  0   0   0   0   0   0   0   0   1   0 239   1   0   0   6  70   1   1\n",
      "    0   0]\n",
      " [  0   0  32   0   0   0   0   2   0   0 329   4   0   0  20   0   1   1\n",
      "    0   0]\n",
      " [  0   0 192   0   0   0   0   0   0   0 195   0   0   0   5   0   2   0\n",
      "    0   0]\n",
      " [  0   0  38   0   0   0   0   0   0   0 340   3   0   0  11   0   0   0\n",
      "    0   0]\n",
      " [  0   0   3   0   0   0   0   1   0   0 369   4   0   0   5   3   0   0\n",
      "    0   0]\n",
      " [  0   0  64   0   0   0   0   0   1   0 312   8   0   0   8   1   0   1\n",
      "    0   0]\n",
      " [  0   0  12   0   0   0   0  17   4   0 335   7   0   0  14   1   0   0\n",
      "    0   0]\n",
      " [  0   0   5   0   0   0   0 133   2   0 252   1   0   0   1   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0  10 101   0 278   3   0   0   1   3   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   1   0 378   8   0   0   2   5   2   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   4   0 382   7   0   0   0   4   1   0\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   2   0   0 227 161   0   0   2   1   1   0\n",
      "    0   0]\n",
      " [  0   0   6   0   0   0   0  12   1   0 351  15   0   0   6   1   1   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   1   1   0 377   2   0   0   1  11   1   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0 272   1   0   0 118   2   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0 218   3   0   0   3 168   0   5\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   1   0   0 285   2   0   0   2   8  63   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   6   3   0 256   9   0   0   2   9   6  85\n",
      "    0   0]\n",
      " [  0   0   4   0   0   0   0   4   0   0 273   2   0   0   1   5  21   0\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   2   0   0 180   1   0   0   1  55   8   2\n",
      "    0   0]]\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diksha/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.417s\n",
      "test time:  0.001s\n",
      "accuracy:   0.129\n",
      "dimensionality: 10\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.22      0.11      0.15       319\n",
      "           comp.graphics       0.04      0.01      0.02       389\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00       394\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.07      0.02      0.03       395\n",
      "            misc.forsale       0.00      0.00      0.00       390\n",
      "               rec.autos       0.68      0.33      0.44       396\n",
      "         rec.motorcycles       0.91      0.25      0.39       398\n",
      "      rec.sport.baseball       0.00      0.00      0.00       397\n",
      "        rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.crypt       0.87      0.33      0.48       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.00      0.00      0.00       396\n",
      "               sci.space       0.64      0.29      0.40       394\n",
      "  soc.religion.christian       0.05      0.78      0.10       398\n",
      "      talk.politics.guns       0.62      0.12      0.20       364\n",
      "   talk.politics.mideast       0.23      0.27      0.25       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "             avg / total       0.22      0.13      0.13      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[ 35   0   0   0   0   0   0   0   1   0   0   1   0   0   5 274   0   3\n",
      "    0   0]\n",
      " [  0   4   0   0   0   7   0   0   0   0   0   0   0   0  10 328   0  39\n",
      "    1   0]\n",
      " [  0  80   0   0   0   1   0   0   0   0   0   0   0   0   3 194   2 113\n",
      "    1   0]\n",
      " [  0   5   0   0   0   4   0   0   0   0   0   1   0   0  10 340   0  32\n",
      "    0   0]\n",
      " [  0   2   0   0   0   4   0   1   0   0   0   0   0   0   4 372   0   2\n",
      "    0   0]\n",
      " [  0  16   0   0   0   7   0   0   0   0   0   1   0   0   5 313   0  53\n",
      "    0   0]\n",
      " [  1   1   0   0   0   6   0  19   3   0   0   1   0   0   5 335   0  19\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0 131   1   0   0   0   0   0   1 252   2   5\n",
      "    3   0]\n",
      " [  2   0   0   0   0   3   0  12  99   0   0   0   0   0   1 280   0   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   5   0   1   1   0   0   4   0   0   2 382   1   1\n",
      "    0   0]\n",
      " [  1   0   0   0   0   4   0   0   3   0   0   3   0   0   0 385   1   2\n",
      "    0   0]\n",
      " [  0   0   0   0   0  32   0   1   0   0   0 132   0   0   0 228   1   1\n",
      "    1   0]\n",
      " [  0   1   0   0   0  12   0  12   1   0   0   4   0   0   6 352   1   4\n",
      "    0   0]\n",
      " [  4   0   0   0   0   1   0   1   0   0   0   1   0   0   0 383   0   6\n",
      "    0   0]\n",
      " [  2   0   0   0   0   0   0   1   0   0   0   1   0   0 114 273   0   3\n",
      "    0   0]\n",
      " [ 76   1   0   0   0   3   0   0   0   0   0   0   0   0   3 310   0   5\n",
      "    0   0]\n",
      " [  3   0   0   0   0   2   0   2   0   0   0   0   0   0   4 290  43  20\n",
      "    0   0]\n",
      " [  5   0   0   0   0   2   0   5   0   0   0   2   0   0   2 260   0 100\n",
      "    0   0]\n",
      " [  2   1   0   0   0   2   0   5   0   0   0   0   0   0   1 275  12  12\n",
      "    0   0]\n",
      " [ 29   0   1   0   0   0   0   3   0   0   0   1   0   0   1 203   6   7\n",
      "    0   0]]\n",
      "\n",
      "================================================================================\n",
      "Passive Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
      "              loss='hinge', n_iter=50, n_jobs=1, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False)\n",
      "train time: 0.323s\n",
      "test time:  0.001s\n",
      "accuracy:   0.170\n",
      "dimensionality: 10\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00       319\n",
      "           comp.graphics       0.00      0.00      0.00       389\n",
      " comp.os.ms-windows.misc       0.55      0.49      0.52       394\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.00      0.00      0.00       395\n",
      "            misc.forsale       0.00      0.00      0.00       390\n",
      "               rec.autos       0.06      0.97      0.12       396\n",
      "         rec.motorcycles       0.85      0.26      0.40       398\n",
      "      rec.sport.baseball       1.00      0.00      0.01       397\n",
      "        rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.crypt       0.69      0.41      0.52       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.00      0.00      0.00       396\n",
      "               sci.space       0.58      0.29      0.39       394\n",
      "  soc.religion.christian       0.50      0.42      0.46       398\n",
      "      talk.politics.guns       0.54      0.17      0.26       364\n",
      "   talk.politics.mideast       0.83      0.23      0.36       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "             avg / total       0.29      0.17      0.16      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[  0   0   0   0   0   0   0 239   1   0   0   1   0   0   6  68   2   2\n",
      "    0   0]\n",
      " [  0   0  23   0   0   3   0 339   0   0   0   3   0   0  18   0   1   2\n",
      "    0   0]\n",
      " [  0   0 192   0   0   0   0 195   0   0   0   0   0   0   4   0   3   0\n",
      "    0   0]\n",
      " [  0   0  38   0   0   0   0 341   0   0   0   3   0   0  10   0   0   0\n",
      "    0   0]\n",
      " [  0   0   3   0   0   0   0 370   0   0   0   4   0   0   5   3   0   0\n",
      "    0   0]\n",
      " [  0   0  60   0   0   0   0 316   1   0   0   8   0   0   8   1   0   1\n",
      "    0   0]\n",
      " [  0   0  13   0   0   0   0 353   4   0   0   7   0   0  12   1   0   0\n",
      "    0   0]\n",
      " [  0   0   5   0   0   0   0 384   3   0   0   1   0   0   1   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0 285 105   0   0   2   0   0   1   3   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0 379   1   1   0   8   0   0   2   4   2   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0 382   4   0   0   7   0   0   0   3   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0 228   0   0   0 163   0   0   2   1   1   1\n",
      "    0   0]\n",
      " [  0   0   5   0   0   0   0 364   1   0   0  15   0   0   6   1   1   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0 378   1   0   0   2   0   0   1  11   1   1\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0 273   0   0   0   2   0   0 116   2   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0 220   0   0   0   1   0   0   3 168   0   5\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0 287   0   0   0   1   0   0   2   8  63   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0 265   3   0   0   6   0   0   2   7   6  87\n",
      "    0   0]\n",
      " [  0   0   3   0   0   0   0 277   0   0   0   2   0   0   1   5  22   0\n",
      "    0   0]\n",
      " [  0   0   3   0   0   0   0 183   0   0   0   1   0   0   1  50   8   5\n",
      "    0   0]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.001s\n",
      "test time:  0.804s\n",
      "accuracy:   0.161\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.23      0.02      0.03       319\n",
      "           comp.graphics       0.43      0.01      0.02       389\n",
      " comp.os.ms-windows.misc       0.06      0.96      0.12       394\n",
      "comp.sys.ibm.pc.hardware       0.05      0.00      0.00       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.25      0.03      0.05       395\n",
      "            misc.forsale       0.50      0.02      0.03       390\n",
      "               rec.autos       0.72      0.31      0.44       396\n",
      "         rec.motorcycles       0.89      0.26      0.40       398\n",
      "      rec.sport.baseball       0.00      0.00      0.00       397\n",
      "        rec.sport.hockey       0.12      0.00      0.00       399\n",
      "               sci.crypt       0.72      0.39      0.50       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.20      0.00      0.00       396\n",
      "               sci.space       0.61      0.29      0.39       394\n",
      "  soc.religion.christian       0.48      0.39      0.43       398\n",
      "      talk.politics.guns       0.58      0.17      0.26       364\n",
      "   talk.politics.mideast       0.87      0.25      0.39       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "             avg / total       0.34      0.16      0.16      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[  5   0 238   1   0   0   0   0   1   0   0   1   0   0   5  64   1   1\n",
      "    0   2]\n",
      " [  0   3 347   1   1  11   1   1   0   0   0   3   0   0  17   0   1   3\n",
      "    0   0]\n",
      " [  0   2 379   3   0   4   0   0   0   0   0   0   0   0   4   0   2   0\n",
      "    0   0]\n",
      " [  0   0 374   1   0   4   1   0   0   0   0   2   0   0  10   0   0   0\n",
      "    0   0]\n",
      " [  1   0 372   0   0   1   0   1   0   0   0   3   0   0   5   2   0   0\n",
      "    0   0]\n",
      " [  0   2 364   2   0  10   1   0   0   0   0   8   0   0   6   1   0   1\n",
      "    0   0]\n",
      " [  0   0 344   2   0   3   6  16   4   0   0   6   1   0   7   1   0   0\n",
      "    0   0]\n",
      " [  0   0 257   6   0   1   0 124   3   0   1   1   0   0   1   0   2   0\n",
      "    0   0]\n",
      " [  0   0 278   1   0   0   0   6 102   0   0   4   0   1   1   3   2   0\n",
      "    0   0]\n",
      " [  0   0 378   0   1   0   1   1   1   0   0   6   0   0   2   4   2   0\n",
      "    0   1]\n",
      " [  0   0 383   0   0   0   0   0   3   0   1   6   1   0   0   4   1   0\n",
      "    0   0]\n",
      " [  0   0 232   1   1   0   1   1   0   2   2 153   0   0   0   2   1   0\n",
      "    0   0]\n",
      " [  0   0 355   0   1   2   0  12   1   0   0  14   0   0   6   1   1   0\n",
      "    0   0]\n",
      " [  1   0 376   1   0   2   0   0   0   0   0   1   1   1   0  10   0   3\n",
      "    0   0]\n",
      " [  0   0 272   0   0   1   1   1   0   0   0   1   1   0 114   3   0   0\n",
      "    0   0]\n",
      " [ 11   0 219   0   0   0   0   0   0   0   1   0   1   0   3 156   0   4\n",
      "    0   3]\n",
      " [  1   0 287   0   0   0   0   1   0   0   1   1   0   0   2   7  62   2\n",
      "    0   0]\n",
      " [  0   0 258   1   0   0   0   4   0   0   2   1   0   2   2   9   2  95\n",
      "    0   0]\n",
      " [  0   0 276   0   0   0   0   3   0   0   0   2   0   1   1   6  21   0\n",
      "    0   0]\n",
      " [  3   0 181   0   0   1   0   2   0   0   0   0   0   0   1  55   8   0\n",
      "    0   0]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "train time: 1.167s\n",
      "test time:  0.335s\n",
      "accuracy:   0.167\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.16      0.03      0.05       319\n",
      "           comp.graphics       0.18      0.02      0.04       389\n",
      " comp.os.ms-windows.misc       0.57      0.33      0.42       394\n",
      "comp.sys.ibm.pc.hardware       0.10      0.01      0.02       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.23      0.04      0.07       395\n",
      "            misc.forsale       0.25      0.03      0.05       390\n",
      "               rec.autos       0.68      0.26      0.37       396\n",
      "         rec.motorcycles       0.76      0.25      0.38       398\n",
      "      rec.sport.baseball       0.06      0.95      0.12       397\n",
      "        rec.sport.hockey       0.09      0.01      0.01       399\n",
      "               sci.crypt       0.79      0.38      0.51       396\n",
      "         sci.electronics       0.06      0.00      0.00       393\n",
      "                 sci.med       0.11      0.00      0.00       396\n",
      "               sci.space       0.65      0.23      0.34       394\n",
      "  soc.religion.christian       0.47      0.26      0.33       398\n",
      "      talk.politics.guns       0.44      0.14      0.21       364\n",
      "   talk.politics.mideast       0.77      0.23      0.36       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.19      0.04      0.07       251\n",
      "\n",
      "             avg / total       0.34      0.17      0.17      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[ 10   0   1   0   0   0   0   0   1 238   2   2   0   0   5  48   1   3\n",
      "    1   7]\n",
      " [  0   8  11   7   1   6   3   2   0 328   1   2   1   1  11   0   4   2\n",
      "    1   0]\n",
      " [  0  17 131  11   1  25   7   1   0 194   0   1   0   0   5   0   1   0\n",
      "    0   0]\n",
      " [  0   5  19   4   2   7   3   0   2 340   0   2   1   0   6   0   0   0\n",
      "    1   0]\n",
      " [  1   0   2   1   0   1   0   0   1 371   0   3   0   0   3   2   0   0\n",
      "    0   0]\n",
      " [  0   8  37   6   0  16   2   1   0 312   0   1   1   2   2   0   3   3\n",
      "    0   1]\n",
      " [  0   1   9   1   0   3  12  11   6 334   0   5   1   0   3   1   1   1\n",
      "    1   0]\n",
      " [  1   0   4   1   0   1   6 102  16 252   3   0   3   0   2   2   1   2\n",
      "    0   0]\n",
      " [  2   1   0   1   0   0   1   7 101 280   1   1   0   1   0   1   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   3   1   0 378   1   5   0   0   0   2   2   0\n",
      "    1   3]\n",
      " [  0   0   1   0   0   0   0   0   3 382   2   4   1   0   0   2   2   0\n",
      "    1   1]\n",
      " [  2   0   1   0   1   4   0   1   0 227   3 149   2   0   1   1   1   1\n",
      "    1   1]\n",
      " [  0   0   5   1   1   2   1  11   1 351   1   9   1   0   4   1   3   0\n",
      "    1   0]\n",
      " [  2   0   0   0   0   0   0   0   0 376   2   1   1   1   1   4   2   3\n",
      "    1   2]\n",
      " [  1   3   3   0   2   2   6   1   1 272   0   1   2   0  90   2   3   1\n",
      "    4   0]\n",
      " [ 26   0   2   4   0   0   0   1   0 218   2   0   1   0   3 102   8   4\n",
      "    0  27]\n",
      " [  2   0   2   0   0   0   3   6   0 285   0   1   0   1   1   6  51   4\n",
      "    2   0]\n",
      " [  5   0   1   0   0   0   0   1   0 256   4   1   1   2   0   9   2  88\n",
      "    4   2]\n",
      " [  2   1   1   1   0   1   0   2   1 271   0   1   1   1   0   6  19   0\n",
      "    0   2]\n",
      " [  8   0   1   3   0   0   1   2   0 180   0   0   0   0   1  30  10   2\n",
      "    2  11]]\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.001, verbose=0)\n",
      "train time: 0.176s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diksha/anaconda2/lib/python2.7/site-packages/sklearn/svm/classes.py:199: DeprecationWarning:\n",
      "\n",
      "loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test time:  0.002s\n",
      "accuracy:   0.186\n",
      "dimensionality: 10\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00       319\n",
      "           comp.graphics       0.00      0.00      0.00       389\n",
      " comp.os.ms-windows.misc       0.52      0.49      0.51       394\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.00      0.00      0.00       395\n",
      "            misc.forsale       0.00      0.00      0.00       390\n",
      "               rec.autos       0.70      0.33      0.45       396\n",
      "         rec.motorcycles       0.85      0.26      0.40       398\n",
      "      rec.sport.baseball       0.00      0.00      0.00       397\n",
      "        rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.crypt       0.67      0.41      0.51       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.06      0.95      0.12       396\n",
      "               sci.space       0.57      0.29      0.39       394\n",
      "  soc.religion.christian       0.49      0.42      0.45       398\n",
      "      talk.politics.guns       0.56      0.17      0.26       364\n",
      "   talk.politics.mideast       0.87      0.23      0.36       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "             avg / total       0.27      0.19      0.18      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[  0   0   0   0   0   0   0   0   1   1   0   1   0 238   6  70   1   1\n",
      "    0   0]\n",
      " [  0   0  32   0   0   1   0   2   0   0   0   4   0 328  20   0   1   1\n",
      "    0   0]\n",
      " [  0   0 193   0   0   0   0   0   0   1   0   0   0 194   4   0   2   0\n",
      "    0   0]\n",
      " [  0   0  39   0   0   0   0   0   0   0   0   3   0 340  10   0   0   0\n",
      "    0   0]\n",
      " [  0   0   3   0   0   0   0   1   0   0   0   4   0 369   5   3   0   0\n",
      "    0   0]\n",
      " [  0   0  64   0   0   0   0   0   1   0   0   8   0 312   8   1   0   1\n",
      "    0   0]\n",
      " [  0   0  13   0   0   0   0  17   4   0   0   7   0 335  13   1   0   0\n",
      "    0   0]\n",
      " [  0   0   5   0   0   0   0 132   3   0   0   1   0 252   1   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   7 105   0   0   2   0 278   1   3   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   1   0   0   8   0 378   2   5   2   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   4   0   0   7   0 382   0   4   1   0\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   1   0   0   0 162   0 227   2   1   1   0\n",
      "    0   0]\n",
      " [  0   0   6   0   0   0   0  12   1   0   0  15   0 351   6   1   1   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   1   1   1   0   2   0 376   1  11   1   1\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   1   0   0   0   2   0 272 116   2   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   3   0 218   3 168   0   5\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   1   0   0   0   2   0 285   2   8  63   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   6   3   1   0   8   0 256   2   8   6  86\n",
      "    0   0]\n",
      " [  0   0   4   0   0   0   0   4   0   2   0   2   0 271   1   5  21   0\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   2   0   0   0   1   0 180   1  54   8   3\n",
      "    0   0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.487s\n",
      "test time:  0.001s\n",
      "accuracy:   0.186\n",
      "dimensionality: 10\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00       319\n",
      "           comp.graphics       0.00      0.00      0.00       389\n",
      " comp.os.ms-windows.misc       0.52      0.49      0.50       394\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.00      0.00      0.00       395\n",
      "            misc.forsale       0.00      0.00      0.00       390\n",
      "               rec.autos       0.69      0.34      0.45       396\n",
      "         rec.motorcycles       0.85      0.26      0.39       398\n",
      "      rec.sport.baseball       0.00      0.00      0.00       397\n",
      "        rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.crypt       0.66      0.41      0.51       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.06      0.95      0.12       396\n",
      "               sci.space       0.57      0.30      0.39       394\n",
      "  soc.religion.christian       0.49      0.42      0.45       398\n",
      "      talk.politics.guns       0.56      0.17      0.26       364\n",
      "   talk.politics.mideast       0.87      0.23      0.36       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "             avg / total       0.27      0.19      0.18      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[  0   0   0   0   0   0   0   0   1   0   0   2   0 238   6  70   1   1\n",
      "    0   0]\n",
      " [  0   0  34   0   0   0   0   2   0   0   0   4   0 328  19   0   1   1\n",
      "    0   0]\n",
      " [  0   0 193   0   0   0   0   0   0   0   0   0   0 194   4   0   3   0\n",
      "    0   0]\n",
      " [  0   0  39   0   0   0   0   0   0   0   0   3   0 340  10   0   0   0\n",
      "    0   0]\n",
      " [  0   0   3   0   0   0   0   1   0   0   0   4   0 369   5   3   0   0\n",
      "    0   0]\n",
      " [  0   0  64   0   0   0   0   0   1   0   0   8   0 312   8   1   0   1\n",
      "    0   0]\n",
      " [  0   0  13   0   0   0   0  18   4   0   0   7   0 334  13   1   0   0\n",
      "    0   0]\n",
      " [  0   0   5   0   0   0   0 133   2   0   0   1   0 252   1   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0  10 102   0   0   2   0 278   1   3   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   1   0   0   8   0 378   2   5   2   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   4   0   0   7   0 382   0   4   1   0\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   1   0   0   0 162   0 227   2   1   1   0\n",
      "    0   0]\n",
      " [  0   0   6   0   0   0   0  12   1   0   0  15   0 351   6   1   1   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   1   1   0   0   3   0 376   1  11   1   1\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   1   0   0   0   1   0 272 117   2   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   3   0 218   3 168   0   5\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   1   0   0   0   2   0 285   2   8  63   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   6   3   0   0   9   0 256   2   8   6  86\n",
      "    0   0]\n",
      " [  0   0   4   0   0   0   0   4   0   0   0   3   0 271   1   6  21   0\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   2   0   0   0   1   0 180   1  54   8   3\n",
      "    0   0]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l1', random_state=None, tol=0.001, verbose=0)\n",
      "train time: 0.023s\n",
      "test time:  0.001s\n",
      "accuracy:   0.186\n",
      "dimensionality: 10\n",
      "density: 0.990000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00       319\n",
      "           comp.graphics       0.00      0.00      0.00       389\n",
      " comp.os.ms-windows.misc       0.52      0.49      0.51       394\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.00      0.00      0.00       395\n",
      "            misc.forsale       0.00      0.00      0.00       390\n",
      "               rec.autos       0.70      0.33      0.45       396\n",
      "         rec.motorcycles       0.85      0.26      0.40       398\n",
      "      rec.sport.baseball       0.00      0.00      0.00       397\n",
      "        rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.crypt       0.67      0.41      0.51       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.06      0.95      0.12       396\n",
      "               sci.space       0.57      0.29      0.39       394\n",
      "  soc.religion.christian       0.49      0.42      0.45       398\n",
      "      talk.politics.guns       0.56      0.17      0.26       364\n",
      "   talk.politics.mideast       0.84      0.23      0.36       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "             avg / total       0.27      0.19      0.18      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[  0   0   0   0   0   0   0   0   1   1   0   1   0 238   6  69   1   2\n",
      "    0   0]\n",
      " [  0   0  33   0   0   1   0   2   0   0   0   4   0 328  19   0   1   1\n",
      "    0   0]\n",
      " [  0   0 193   0   0   0   0   0   0   1   0   0   0 194   4   0   2   0\n",
      "    0   0]\n",
      " [  0   0  39   0   0   0   0   0   0   0   0   3   0 340  10   0   0   0\n",
      "    0   0]\n",
      " [  0   0   3   0   0   0   0   1   0   0   0   4   0 369   5   3   0   0\n",
      "    0   0]\n",
      " [  0   0  64   0   0   0   0   0   1   0   0   8   0 312   8   1   0   1\n",
      "    0   0]\n",
      " [  0   0  13   0   0   0   0  17   4   0   0   7   0 335  13   1   0   0\n",
      "    0   0]\n",
      " [  0   0   5   0   0   0   0 132   3   0   0   1   0 252   1   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   7 105   0   0   2   0 278   1   3   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   1   0   0   8   0 378   2   5   2   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   4   0   0   7   0 382   0   4   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0 163   0 227   2   1   1   1\n",
      "    0   0]\n",
      " [  0   0   6   0   0   0   0  12   1   0   0  15   0 351   6   1   1   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   1   1   1   0   2   0 376   1  11   1   1\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   1   0   0   0   2   0 272 116   2   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   3   0 218   3 168   0   5\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   1   0   0   0   2   0 285   2   8  63   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   6   3   2   0   7   0 256   2   7   6  87\n",
      "    0   0]\n",
      " [  0   0   4   0   0   0   0   4   0   2   0   2   0 271   1   5  21   0\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   2   0   0   0   1   0 180   1  52   8   5\n",
      "    0   0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diksha/anaconda2/lib/python2.7/site-packages/sklearn/svm/classes.py:199: DeprecationWarning:\n",
      "\n",
      "loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.433s\n",
      "test time:  0.001s\n",
      "accuracy:   0.162\n",
      "dimensionality: 10\n",
      "density: 0.455000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00       319\n",
      "           comp.graphics       0.00      0.00      0.00       389\n",
      " comp.os.ms-windows.misc       0.06      0.98      0.12       394\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.00      0.00      0.00       395\n",
      "            misc.forsale       0.00      0.00      0.00       390\n",
      "               rec.autos       0.69      0.33      0.45       396\n",
      "         rec.motorcycles       0.85      0.26      0.40       398\n",
      "      rec.sport.baseball       0.00      0.00      0.00       397\n",
      "        rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.crypt       0.66      0.41      0.50       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.00      0.00      0.00       396\n",
      "               sci.space       0.57      0.29      0.39       394\n",
      "  soc.religion.christian       0.49      0.42      0.46       398\n",
      "      talk.politics.guns       0.56      0.17      0.26       364\n",
      "   talk.politics.mideast       0.84      0.23      0.36       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "             avg / total       0.24      0.16      0.15      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[  0   0 238   0   0   0   0   0   1   0   0   2   0   0   6  68   2   2\n",
      "    0   0]\n",
      " [  0   0 362   0   0   0   0   2   0   0   0   4   0   0  19   0   1   1\n",
      "    0   0]\n",
      " [  0   0 386   0   0   0   0   1   0   0   0   1   0   0   4   0   2   0\n",
      "    0   0]\n",
      " [  0   0 379   0   0   0   0   0   0   0   0   3   0   0  10   0   0   0\n",
      "    0   0]\n",
      " [  0   0 372   0   0   0   0   1   0   0   0   4   0   0   5   3   0   0\n",
      "    0   0]\n",
      " [  0   0 377   0   0   0   0   0   1   0   0   7   0   0   8   1   0   1\n",
      "    0   0]\n",
      " [  0   0 347   0   0   0   0  17   4   0   0   7   0   0  14   1   0   0\n",
      "    0   0]\n",
      " [  0   0 257   0   0   0   0 132   3   0   0   1   0   0   1   0   2   0\n",
      "    0   0]\n",
      " [  0   0 278   0   0   0   0   7 105   0   0   2   0   0   1   3   2   0\n",
      "    0   0]\n",
      " [  0   0 378   0   0   0   0   1   1   0   0   8   0   0   2   5   2   0\n",
      "    0   0]\n",
      " [  0   0 383   0   0   0   0   0   4   0   0   7   0   0   0   4   1   0\n",
      "    0   0]\n",
      " [  0   0 229   0   0   0   0   1   0   0   0 161   0   0   2   1   1   1\n",
      "    0   0]\n",
      " [  0   0 357   0   0   0   0  12   1   0   0  15   0   0   6   1   1   0\n",
      "    0   0]\n",
      " [  0   0 377   0   0   0   0   1   1   0   0   3   0   0   1  11   1   1\n",
      "    0   0]\n",
      " [  0   0 273   0   0   0   0   1   0   0   0   2   0   0 116   2   0   0\n",
      "    0   0]\n",
      " [  0   0 219   0   0   0   0   0   0   0   0   3   0   0   3 168   0   5\n",
      "    0   0]\n",
      " [  0   0 287   0   0   0   0   1   0   0   0   2   0   0   2   8  63   1\n",
      "    0   0]\n",
      " [  0   0 256   0   0   0   0   6   3   0   0   9   0   0   2   7   6  87\n",
      "    0   0]\n",
      " [  0   0 275   0   0   0   0   4   0   0   0   3   0   0   1   6  21   0\n",
      "    0   0]\n",
      " [  0   0 182   0   0   0   0   3   0   0   0   1   0   0   1  51   8   5\n",
      "    0   0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
    "                                            dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train SGD with Elastic Net penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.488s\n",
      "test time:  0.001s\n",
      "accuracy:   0.180\n",
      "dimensionality: 10\n",
      "density: 0.845000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00       319\n",
      "           comp.graphics       0.06      0.84      0.11       389\n",
      " comp.os.ms-windows.misc       0.52      0.49      0.50       394\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.00      0.00      0.00       395\n",
      "            misc.forsale       0.00      0.00      0.00       390\n",
      "               rec.autos       0.69      0.34      0.45       396\n",
      "         rec.motorcycles       0.85      0.26      0.39       398\n",
      "      rec.sport.baseball       0.00      0.00      0.00       397\n",
      "        rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.crypt       0.66      0.41      0.51       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.00      0.00      0.00       396\n",
      "               sci.space       0.57      0.30      0.39       394\n",
      "  soc.religion.christian       0.49      0.42      0.45       398\n",
      "      talk.politics.guns       0.56      0.17      0.26       364\n",
      "   talk.politics.mideast       0.87      0.23      0.36       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "             avg / total       0.27      0.18      0.18      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[  0 238   0   0   0   0   0   0   1   0   0   2   0   0   6  70   1   1\n",
      "    0   0]\n",
      " [  0 328  34   0   0   0   0   2   0   0   0   4   0   0  19   0   1   1\n",
      "    0   0]\n",
      " [  0 194 193   0   0   0   0   0   0   0   0   0   0   0   4   0   3   0\n",
      "    0   0]\n",
      " [  0 340  39   0   0   0   0   0   0   0   0   3   0   0  10   0   0   0\n",
      "    0   0]\n",
      " [  0 369   3   0   0   0   0   1   0   0   0   4   0   0   5   3   0   0\n",
      "    0   0]\n",
      " [  0 312  64   0   0   0   0   0   1   0   0   8   0   0   8   1   0   1\n",
      "    0   0]\n",
      " [  0 334  13   0   0   0   0  18   4   0   0   7   0   0  13   1   0   0\n",
      "    0   0]\n",
      " [  0 252   5   0   0   0   0 133   2   0   0   1   0   0   1   0   2   0\n",
      "    0   0]\n",
      " [  0 278   0   0   0   0   0  10 102   0   0   2   0   0   1   3   2   0\n",
      "    0   0]\n",
      " [  0 378   0   0   0   0   0   1   1   0   0   8   0   0   2   5   2   0\n",
      "    0   0]\n",
      " [  0 382   1   0   0   0   0   0   4   0   0   7   0   0   0   4   1   0\n",
      "    0   0]\n",
      " [  0 227   2   0   0   0   0   1   0   0   0 162   0   0   2   1   1   0\n",
      "    0   0]\n",
      " [  0 351   6   0   0   0   0  12   1   0   0  15   0   0   6   1   1   0\n",
      "    0   0]\n",
      " [  0 376   1   0   0   0   0   1   1   0   0   3   0   0   1  11   1   1\n",
      "    0   0]\n",
      " [  0 272   1   0   0   0   0   1   0   0   0   1   0   0 117   2   0   0\n",
      "    0   0]\n",
      " [  0 218   1   0   0   0   0   0   0   0   0   3   0   0   3 168   0   5\n",
      "    0   0]\n",
      " [  0 285   2   0   0   0   0   1   0   0   0   2   0   0   2   8  63   1\n",
      "    0   0]\n",
      " [  0 256   0   0   0   0   0   6   3   0   0   9   0   0   2   8   6  86\n",
      "    0   0]\n",
      " [  0 271   4   0   0   0   0   4   0   0   0   3   0   0   1   6  21   0\n",
      "    0   0]\n",
      " [  0 180   2   0   0   0   0   2   0   0   0   1   0   0   1  54   8   3\n",
      "    0   0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                       penalty=\"elasticnet\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train NearestCentroid without threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.020s\n",
      "test time:  0.002s\n",
      "accuracy:   0.180\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.17      0.01      0.02       319\n",
      "           comp.graphics       1.00      0.01      0.02       389\n",
      " comp.os.ms-windows.misc       0.57      0.48      0.52       394\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.22      0.02      0.04       395\n",
      "            misc.forsale       0.00      0.00      0.00       390\n",
      "               rec.autos       0.70      0.34      0.45       396\n",
      "         rec.motorcycles       0.90      0.25      0.39       398\n",
      "      rec.sport.baseball       0.00      0.00      0.00       397\n",
      "        rec.sport.hockey       0.17      0.00      0.00       399\n",
      "               sci.crypt       0.71      0.34      0.46       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.06      0.95      0.12       396\n",
      "               sci.space       0.61      0.29      0.40       394\n",
      "  soc.religion.christian       0.50      0.36      0.42       398\n",
      "      talk.politics.guns       0.58      0.16      0.26       364\n",
      "   talk.politics.mideast       0.90      0.23      0.36       376\n",
      "      talk.politics.misc       0.03      0.00      0.01       310\n",
      "      talk.religion.misc       0.18      0.04      0.06       251\n",
      "\n",
      "             avg / total       0.37      0.18      0.18      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[  3   0   0   0   0   0   0   0   1   0   0   0   1 238   5  58   1   1\n",
      "    2   9]\n",
      " [  0   3  21   1   3  11   0   0   0   0   0   3   2 328  15   0   1   1\n",
      "    0   0]\n",
      " [  0   0 188   0   0   5   0   0   0   0   0   0   0 194   4   0   2   0\n",
      "    1   0]\n",
      " [  0   0  33   0   0   5   0   0   0   0   0   1   1 341  11   0   0   0\n",
      "    0   0]\n",
      " [  1   0   3   0   0   0   0   1   0   0   0   4   0 369   5   0   0   0\n",
      "    0   2]\n",
      " [  0   0  56   1   2   8   0   0   0   0   0   7   1 313   5   1   0   1\n",
      "    0   0]\n",
      " [  0   0  13   0   7   0   0  18   4   0   0   6   1 334   6   1   0   0\n",
      "    0   0]\n",
      " [  0   0   5   0   0   1   0 133   1   0   0   1   0 252   1   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0  11  99   0   1   3   0 278   1   4   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   1   0   0   5   1 378   2   4   2   0\n",
      "    2   1]\n",
      " [  0   0   1   0   0   0   0   0   3   0   1   6   0 382   0   3   1   0\n",
      "    2   0]\n",
      " [  0   0   2   0   0   0   0   2   0   0   0 133   3 228   2   2   2   0\n",
      "   22   0]\n",
      " [  0   0   3   0   0   3   0  12   1   0   0  15   0 351   6   1   1   0\n",
      "    0   0]\n",
      " [  1   0   0   0   1   1   0   0   0   1   1   1   3 376   0   9   0   0\n",
      "    1   1]\n",
      " [  0   0   0   0   1   0   0   1   0   0   0   0   0 272 116   3   0   0\n",
      "    1   0]\n",
      " [  6   0   1   0   0   0   0   0   0   0   0   0   3 218   3 142   0   5\n",
      "    0  20]\n",
      " [  0   0   2   0   0   0   1   2   0   0   0   1   1 285   3   6  60   1\n",
      "    0   2]\n",
      " [  0   0   0   0   0   0   2   3   0   0   3   0   7 258   2   6   2  85\n",
      "    5   3]\n",
      " [  1   0   2   1   0   1   0   4   0   1   0   1   1 271   1   3  20   0\n",
      "    1   2]\n",
      " [  6   0   1   0   0   1   0   2   0   0   0   0   0 180   1  43   8   0\n",
      "    0   9]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train sparse Naive Bayes classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.009s\n",
      "test time:  0.001s\n",
      "accuracy:   0.183\n",
      "dimensionality: 10\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00       319\n",
      "           comp.graphics       0.19      0.01      0.01       389\n",
      " comp.os.ms-windows.misc       0.54      0.47      0.50       394\n",
      "comp.sys.ibm.pc.hardware       0.33      0.00      0.01       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.27      0.01      0.01       395\n",
      "            misc.forsale       0.00      0.00      0.00       390\n",
      "               rec.autos       0.71      0.32      0.44       396\n",
      "         rec.motorcycles       0.85      0.26      0.40       398\n",
      "      rec.sport.baseball       0.08      0.01      0.02       397\n",
      "        rec.sport.hockey       0.07      0.96      0.12       399\n",
      "               sci.crypt       0.79      0.36      0.49       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.14      0.00      0.00       396\n",
      "               sci.space       0.59      0.29      0.39       394\n",
      "  soc.religion.christian       0.48      0.42      0.45       398\n",
      "      talk.politics.guns       0.60      0.17      0.26       364\n",
      "   talk.politics.mideast       0.90      0.23      0.36       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "             avg / total       0.34      0.18      0.18      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[  0   0   0   0   0   0   0   0   1   0 239   1   0   0   5  71   1   1\n",
      "    0   0]\n",
      " [  0   3  29   0   4   2   1   1   0   2 328   2   0   1  14   0   1   1\n",
      "    0   0]\n",
      " [  0   5 184   0   0   3   1   0   0   0 195   0   0   0   4   0   2   0\n",
      "    0   0]\n",
      " [  0   1  35   1   0   2   0   0   0   2 340   1   0   0  10   0   0   0\n",
      "    0   0]\n",
      " [  0   0   3   0   0   0   0   1   0   3 369   1   0   0   5   3   0   0\n",
      "    0   0]\n",
      " [  0   4  58   0   0   3   0   0   0   0 313   7   0   1   7   1   0   1\n",
      "    0   0]\n",
      " [  0   1  12   0   0   0   0  17   4   5 335   2   1   0  12   1   0   0\n",
      "    0   0]\n",
      " [  0   0   5   0   0   0   3 127   3   0 252   1   2   0   1   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   7 104   2 278   1   0   0   1   3   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   1   5 378   4   0   0   3   4   1   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   4   4 382   3   0   0   0   4   1   0\n",
      "    0   0]\n",
      " [  0   0   0   2   2   0   0   1   0  17 228 142   0   1   0   2   1   0\n",
      "    0   0]\n",
      " [  0   1   4   0   0   1   0  12   1   7 351   8   0   0   6   1   1   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   1   1 379   1   1   1   0  11   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   1   0   0   1   0   0 272   1   0   1 115   2   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   4 218   0   0   1   3 167   0   4\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   1   1   0   2 285   0   0   0   3   8  61   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   5   3   3 261   4   2   0   3   9   1  85\n",
      "    0   0]\n",
      " [  0   0   4   0   0   0   0   3   0   2 273   0   1   0   1   6  20   0\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   2   0   0 181   0   0   1   1  55   8   1\n",
      "    0   0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.006s\n",
      "test time:  0.001s\n",
      "accuracy:   0.184\n",
      "dimensionality: 10\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00       319\n",
      "           comp.graphics       0.00      0.00      0.00       389\n",
      " comp.os.ms-windows.misc       0.52      0.49      0.50       394\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.00      0.00      0.00       395\n",
      "            misc.forsale       0.00      0.00      0.00       390\n",
      "               rec.autos       0.69      0.33      0.45       396\n",
      "         rec.motorcycles       0.85      0.26      0.40       398\n",
      "      rec.sport.baseball       0.06      0.95      0.12       397\n",
      "        rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.crypt       0.65      0.41      0.50       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.00      0.00      0.00       396\n",
      "               sci.space       0.58      0.29      0.39       394\n",
      "  soc.religion.christian       0.47      0.42      0.44       398\n",
      "      talk.politics.guns       0.53      0.16      0.24       364\n",
      "   talk.politics.mideast       0.87      0.22      0.35       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.25      0.00      0.01       251\n",
      "\n",
      "             avg / total       0.28      0.18      0.18      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[  0   0   0   0   0   0   0   0   1 238   0   2   0   0   5  70   2   1\n",
      "    0   0]\n",
      " [  0   0  36   0   0   0   0   2   0 328   0   4   0   0  16   0   1   2\n",
      "    0   0]\n",
      " [  0   0 193   0   0   0   0   1   0 194   0   1   0   0   3   0   2   0\n",
      "    0   0]\n",
      " [  0   0  39   0   0   0   0   0   0 340   0   3   0   0  10   0   0   0\n",
      "    0   0]\n",
      " [  0   0   3   0   0   0   0   1   0 369   0   5   0   0   4   3   0   0\n",
      "    0   0]\n",
      " [  0   0  65   0   0   0   0   0   1 312   0   7   0   0   8   1   0   1\n",
      "    0   0]\n",
      " [  0   0  13   0   0   0   0  18   4 334   0   7   0   0  12   2   0   0\n",
      "    0   0]\n",
      " [  0   0   5   0   0   0   1 130   3 252   0   1   0   0   1   0   3   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   7 105 278   0   2   0   0   1   3   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   1 378   0   8   0   0   3   4   1   0\n",
      "    0   1]\n",
      " [  0   0   1   0   0   0   0   0   4 382   0   7   0   0   0   4   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 227   0 162   0   0   2   2   2   1\n",
      "    0   0]\n",
      " [  0   0   6   0   0   0   0  11   1 351   0  15   0   0   6   1   2   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   1   1 376   0   3   0   0   1  11   1   1\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   2   0 272   0   1   0   0 114   3   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   0 218   0   3   0   0   2 166   1   5\n",
      "    0   2]\n",
      " [  0   0   2   0   0   0   0   1   0 285   0   5   0   0   5   8  57   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   6   3 256   0   9   0   0   3  11   5  83\n",
      "    0   0]\n",
      " [  0   0   4   0   0   0   0   4   0 271   0   4   0   0   1   6  20   0\n",
      "    0   0]\n",
      " [  0   0   3   0   0   0   0   3   0 180   0   0   0   0   1  55   8   0\n",
      "    0   1]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC with L1-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection', LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)), ('classification', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diksha/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning:\n",
      "\n",
      "Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.436s\n",
      "test time:  0.002s\n",
      "accuracy:   0.186\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00       319\n",
      "           comp.graphics       0.00      0.00      0.00       389\n",
      " comp.os.ms-windows.misc       0.52      0.49      0.51       394\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.00      0.00      0.00       395\n",
      "            misc.forsale       0.00      0.00      0.00       390\n",
      "               rec.autos       0.70      0.33      0.45       396\n",
      "         rec.motorcycles       0.85      0.26      0.40       398\n",
      "      rec.sport.baseball       0.00      0.00      0.00       397\n",
      "        rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.crypt       0.67      0.41      0.51       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.06      0.95      0.12       396\n",
      "               sci.space       0.57      0.29      0.39       394\n",
      "  soc.religion.christian       0.49      0.42      0.45       398\n",
      "      talk.politics.guns       0.56      0.17      0.26       364\n",
      "   talk.politics.mideast       0.87      0.23      0.36       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "             avg / total       0.27      0.19      0.18      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[  0   0   0   0   0   0   0   0   1   1   0   1   0 238   6  70   1   1\n",
      "    0   0]\n",
      " [  0   0  32   0   0   1   0   2   0   0   0   4   0 328  20   0   1   1\n",
      "    0   0]\n",
      " [  0   0 193   0   0   0   0   0   0   1   0   0   0 194   4   0   2   0\n",
      "    0   0]\n",
      " [  0   0  39   0   0   0   0   0   0   0   0   3   0 340  10   0   0   0\n",
      "    0   0]\n",
      " [  0   0   3   0   0   0   0   1   0   0   0   4   0 369   5   3   0   0\n",
      "    0   0]\n",
      " [  0   0  64   0   0   0   0   0   1   0   0   8   0 312   8   1   0   1\n",
      "    0   0]\n",
      " [  0   0  13   0   0   0   0  17   4   0   0   7   0 335  13   1   0   0\n",
      "    0   0]\n",
      " [  0   0   5   0   0   0   0 132   3   0   0   1   0 252   1   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   7 105   0   0   2   0 278   1   3   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   1   0   0   8   0 378   2   5   2   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   4   0   0   7   0 382   0   4   1   0\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   1   0   0   0 162   0 227   2   1   1   0\n",
      "    0   0]\n",
      " [  0   0   6   0   0   0   0  12   1   0   0  15   0 351   6   1   1   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   1   1   1   0   2   0 376   1  11   1   1\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   1   0   0   0   2   0 272 116   2   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   3   0 218   3 168   0   5\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   1   0   0   0   2   0 285   2   8  63   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   6   3   1   0   8   0 256   2   8   6  86\n",
      "    0   0]\n",
      " [  0   0   4   0   0   0   0   4   0   2   0   2   0 271   1   5  21   0\n",
      "    0   0]\n",
      " [  0   0   2   0   0   0   0   2   0   0   0   1   0 180   1  54   8   3\n",
      "    0   0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diksha/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning:\n",
      "\n",
      "Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "  ('classification', LinearSVC())\n",
    "])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "p1 = go.Bar(x=indices, y=score, \n",
    "            name=\"score\", \n",
    "            marker=dict(color='navy'))\n",
    "\n",
    "p2 = go.Bar(x=indices + 2, y=training_time, \n",
    "            name=\"training time\",\n",
    "            marker=dict(color='cyan'))\n",
    "\n",
    "p3 = go.Bar(x=indices + 4, y=test_time, \n",
    "            name=\"test time\", \n",
    "            marker=dict(color='darkorange'))\n",
    "\n",
    "\n",
    "layout = go.Layout(title=\"Score\")\n",
    "fig = go.Figure(data=[p1, p2, p3], layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Diksha_Gabha/3596.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: \n",
    "    \n",
    "         Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "         \n",
    "         Olivier Grisel <olivier.grisel@ensta.org>\n",
    "         \n",
    "         Mathieu Blondel <mathieu@mblondel.org>\n",
    "         \n",
    "         Lars Buitinck\n",
    "        \n",
    "License: \n",
    "    \n",
    "         BSD 3 clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href=\"//fonts.googleapis.com/css?family=Open+Sans:600,400,300,200|Inconsolata|Ubuntu+Mono:400,700\" rel=\"stylesheet\" type=\"text/css\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"http://help.plot.ly/documentation/all_static/css/ipython-notebook-custom.css\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/plotly/publisher.git\n",
      "  Cloning https://github.com/plotly/publisher.git to /tmp/pip-jpH4Ro-build\n",
      "Installing collected packages: publisher\n",
      "  Found existing installation: publisher 0.10\n",
      "    Uninstalling publisher-0.10:\n",
      "      Successfully uninstalled publisher-0.10\n",
      "  Running setup.py install for publisher ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25hSuccessfully installed publisher-0.10\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML('<link href=\"//fonts.googleapis.com/css?family=Open+Sans:600,400,300,200|Inconsolata|Ubuntu+Mono:400,700\" rel=\"stylesheet\" type=\"text/css\" />'))\n",
    "display(HTML('<link rel=\"stylesheet\" type=\"text/css\" href=\"http://help.plot.ly/documentation/all_static/css/ipython-notebook-custom.css\">'))\n",
    "\n",
    "! pip install git+https://github.com/plotly/publisher.git --upgrade\n",
    "import publisher\n",
    "publisher.publish(\n",
    "    'Classification of Text Documents using Sparse Features.ipynb', 'scikit-learn/document-classification-20newsgroups/', 'Classification of Text Documents using Sparse Features | plotly',\n",
    "    ' ',\n",
    "    title = 'Classification of Text Documents using Sparse Features | plotly',\n",
    "    name = 'Classification of Text Documents using Sparse Features',\n",
    "    has_thumbnail='false', thumbnail='thumbnail/your-tutorial-chart.jpg', \n",
    "    language='scikit-learn', page_type='example_index',\n",
    "    display_as='text_documents', order=4,\n",
    "    ipynb= '~Diksha_Gabha/3598')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
