{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compares FeatureHasher and DictVectorizer by using both to vectorize text documents.\n",
    "\n",
    "The example demonstrates syntax and speed only; it doesnâ€™t actually do anything useful with the extracted vectors. See the example scripts {document_classification_20newsgroups,clustering}.py for actual learning on text documents.\n",
    "\n",
    "A discrepancy between the number of terms reported for DictVectorizer and for FeatureHasher is to be expected due to hash collisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New to Plotly?\n",
    "Plotly's Python library is free and open source! [Get started](https://plot.ly/python/getting-started/) by downloading the client and [reading the primer](https://plot.ly/python/getting-started/).\n",
    "<br>You can set up Plotly to work in [online](https://plot.ly/python/getting-started/#initialization-for-online-plotting) or [offline](https://plot.ly/python/getting-started/#initialization-for-offline-plotting) mode, or in [jupyter notebooks](https://plot.ly/python/getting-started/#start-plotting-online).\n",
    "<br>We also have a quick-reference [cheatsheet](https://images.plot.ly/plotly-documentation/images/python_cheat_sheet.pdf) (new!) to help you get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial imports [fetch_20newsgroups](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups), [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html#sklearn.feature_extraction.DictVectorizer) and [FeatureHasher](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html#sklearn.feature_extraction.FeatureHasher)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction import DictVectorizer, FeatureHasher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def n_nonzero_columns(X):\n",
    "    \"\"\"Returns the number of non-zero columns in a CSR matrix X.\"\"\"\n",
    "    return len(np.unique(X.nonzero()[1]))\n",
    "\n",
    "\n",
    "def tokens(doc):\n",
    "    \"\"\"Extract tokens from doc.\n",
    "\n",
    "    This uses a simple regex to break strings into tokens. For a more\n",
    "    principled approach, see CountVectorizer or TfidfVectorizer.\n",
    "    \"\"\"\n",
    "    return (tok.lower() for tok in re.findall(r\"\\w+\", doc))\n",
    "\n",
    "\n",
    "def token_freqs(doc):\n",
    "    \"\"\"Extract a dict mapping tokens from doc to their frequencies.\"\"\"\n",
    "    freq = defaultdict(int)\n",
    "    for tok in tokens(doc):\n",
    "        freq[tok] += 1\n",
    "    return freq\n",
    "\n",
    "\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'comp.graphics',\n",
    "    'comp.sys.ibm.pc.hardware',\n",
    "    'misc.forsale',\n",
    "    'rec.autos',\n",
    "    'sci.space',\n",
    "    'talk.religion.misc',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a larger set (11k+ documents) set `categories = None`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default number of features is 2**18.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups training data\n",
      "3803 documents - 6.245MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_features = 2 ** 18\n",
    "\n",
    "print(\"Loading 20 newsgroups training data\")\n",
    "raw_data = fetch_20newsgroups(subset='train', categories=categories).data\n",
    "data_size_mb = sum(len(s.encode('utf-8')) for s in raw_data) / 1e6\n",
    "print(\"%d documents - %0.3fMB\" % (len(raw_data), data_size_mb))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DictVectorizer\n",
      "done in 1.647244s at 3.791MB/s\n",
      "Found 47918 unique terms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DictVectorizer\")\n",
    "t0 = time()\n",
    "vectorizer = DictVectorizer()\n",
    "vectorizer.fit_transform(token_freqs(d) for d in raw_data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_size_mb / duration))\n",
    "print(\"Found %d unique terms\" % len(vectorizer.get_feature_names()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureHasher on frequency dicts\n",
      "done in 1.319619s at 4.732MB/s\n",
      "Found 43865 unique terms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"FeatureHasher on frequency dicts\")\n",
    "t0 = time()\n",
    "hasher = FeatureHasher(n_features=n_features)\n",
    "X = hasher.transform(token_freqs(d) for d in raw_data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_size_mb / duration))\n",
    "print(\"Found %d unique terms\" % n_nonzero_columns(X))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureHasher on raw tokens\n",
      "done in 1.444398s at 4.323MB/s\n",
      "Found 43865 unique terms\n"
     ]
    }
   ],
   "source": [
    "print(\"FeatureHasher on raw tokens\")\n",
    "t0 = time()\n",
    "hasher = FeatureHasher(n_features=n_features, input_type=\"string\")\n",
    "X = hasher.transform(tokens(d) for d in raw_data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_size_mb / duration))\n",
    "print(\"Found %d unique terms\" % n_nonzero_columns(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: \n",
    "\n",
    "        Lars Buitinck\n",
    "\n",
    "License:\n",
    "\n",
    "        BSD 3 clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href=\"//fonts.googleapis.com/css?family=Open+Sans:600,400,300,200|Inconsolata|Ubuntu+Mono:400,700\" rel=\"stylesheet\" type=\"text/css\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"http://help.plot.ly/documentation/all_static/css/ipython-notebook-custom.css\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/plotly/publisher.git\n",
      "  Cloning https://github.com/plotly/publisher.git to /tmp/pip-2ktOQw-build\n",
      "Installing collected packages: publisher\n",
      "  Found existing installation: publisher 0.10\n",
      "    Uninstalling publisher-0.10:\n",
      "      Successfully uninstalled publisher-0.10\n",
      "  Running setup.py install for publisher ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25hSuccessfully installed publisher-0.10\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML('<link href=\"//fonts.googleapis.com/css?family=Open+Sans:600,400,300,200|Inconsolata|Ubuntu+Mono:400,700\" rel=\"stylesheet\" type=\"text/css\" />'))\n",
    "display(HTML('<link rel=\"stylesheet\" type=\"text/css\" href=\"http://help.plot.ly/documentation/all_static/css/ipython-notebook-custom.css\">'))\n",
    "\n",
    "! pip install git+https://github.com/plotly/publisher.git --upgrade\n",
    "import publisher\n",
    "publisher.publish(\n",
    "    'FeatureHasher and DictVectorizer Comparison.ipynb', 'scikit-learn/hashing-vs-dict-vectorizer/', 'FeatureHasher and DictVectorizer Comparison | plotly',\n",
    "    ' ',\n",
    "    title = 'FeatureHasher and DictVectorizer Comparison | plotly',\n",
    "    name = 'FeatureHasher and DictVectorizer Comparison',\n",
    "    has_thumbnail='false', thumbnail='thumbnail/your-tutorial-chart.jpg', \n",
    "    language='scikit-learn', page_type='example_index',\n",
    "    display_as='text_documents', order=1,\n",
    "    ipynb= '~Diksha_Gabha/3573')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
