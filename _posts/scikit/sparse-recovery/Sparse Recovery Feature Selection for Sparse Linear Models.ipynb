{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a small number of observations, we want to recover which features of X are relevant to explain y. For this [sparse linear models](http://scikit-learn.org/stable/modules/feature_selection.html#l1-feature-selection) can outperform standard statistical tests if the true model is sparse, i.e. if a small fraction of the features are relevant.\n",
    "\n",
    "As detailed in the [compressive sensing notes](http://scikit-learn.org/stable/modules/feature_selection.html#compressive-sensing), the ability of L1-based approach to identify the relevant variables depends on the sparsity of the ground truth, the number of samples, the number of features, the conditioning of the design matrix on the signal subspace, the amount of noise, and the absolute value of the smallest non-zero coefficient [Wainwright2006] (http://statistics.berkeley.edu/sites/default/files/tech-reports/709.pdf).\n",
    "\n",
    "Here we keep all parameters constant and vary the conditioning of the design matrix. For a well-conditioned design matrix (small mutual incoherence) we are exactly in compressive sensing conditions (i.i.d Gaussian sensing matrix), and L1-recovery with the Lasso performs very well. For an ill-conditioned matrix (high mutual incoherence), regressors are very correlated, and the Lasso randomly selects one. However, randomized-Lasso can recover the ground truth well.\n",
    "\n",
    "In each situation, we first vary the alpha parameter setting the sparsity of the estimated model and look at the stability scores of the randomized Lasso. This analysis, knowing the ground truth, shows an optimal regime in which relevant features stand out from the irrelevant ones. If alpha is chosen too small, non-relevant variables enter the model. On the opposite, if alpha is selected too large, the Lasso is equivalent to stepwise regression, and thus brings no advantage over a univariate F-test.\n",
    "In a second time, we set alpha and compare the performance of different feature selection methods, using the area under curve (AUC) of the precision-recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New to Plotly?\n",
    "Plotly's Python library is free and open source! [Get started](https://plot.ly/python/getting-started/) by downloading the client and [reading the primer](https://plot.ly/python/getting-started/).\n",
    "<br>You can set up Plotly to work in [online](https://plot.ly/python/getting-started/#initialization-for-online-plotting) or [offline](https://plot.ly/python/getting-started/#initialization-for-offline-plotting) mode, or in [jupyter notebooks](https://plot.ly/python/getting-started/#start-plotting-online).\n",
    "<br>We also have a quick-reference [cheatsheet](https://images.plot.ly/plotly-documentation/images/python_cheat_sheet.pdf) (new!) to help you get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial imports [RandomizedLasso](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RandomizedLasso.html#sklearn.linear_model.RandomizedLasso), [lasso_stability_path](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.lasso_stability_path.html#sklearn.linear_model.lasso_stability_path), [LassoLarsCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV), [f_regression](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression), [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler), [precision_recall_curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve), [auc](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html#sklearn.metrics.auc), [ExtraTreesRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor),  and [ConvergenceWarning](http://scikit-learn.org/stable/modules/generated/sklearn.exceptions.ConvergenceWarning.html#sklearn.exceptions.ConvergenceWarning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "from sklearn.linear_model import (RandomizedLasso, lasso_stability_path,\n",
    "                                  LassoLarsCV)\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.utils.extmath import pinvh\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutual_incoherence(X_relevant, X_irelevant):\n",
    "    \"\"\"Mutual incoherence, as defined by formula (26a) of [Wainwright2006].\n",
    "    \"\"\"\n",
    "    projector = np.dot(np.dot(X_irelevant.T, X_relevant),\n",
    "                       pinvh(np.dot(X_relevant.T, X_relevant)))\n",
    "    return np.max(np.abs(projector).sum(axis=1))\n",
    "\n",
    "data = []\n",
    "k = 0\n",
    "titles = []\n",
    "\n",
    "def data_to_plotly(coefs):\n",
    "    y_ = []\n",
    "\n",
    "    for col in range(0, len(coefs[0])):\n",
    "        y_.append([ ])\n",
    "        for row in range(0, len(coefs)):\n",
    "            y_[col].append(coefs[row][col])\n",
    "    \n",
    "    return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for conditioning in (1, 1e-4):\n",
    "    \n",
    "    # Simulate regression data with a correlated design\n",
    "    n_features = 501\n",
    "    n_relevant_features = 3\n",
    "    noise_level = .2\n",
    "    coef_min = .2\n",
    "    # The Donoho-Tanner phase transition is around n_samples=25: below we\n",
    "    # will completely fail to recover in the well-conditioned case\n",
    "    n_samples = 25\n",
    "    block_size = n_relevant_features\n",
    "\n",
    "    rng = np.random.RandomState(42)\n",
    "\n",
    "    # The coefficients of our model\n",
    "    coef = np.zeros(n_features)\n",
    "    coef[:n_relevant_features] = coef_min + rng.rand(n_relevant_features)\n",
    "\n",
    "    # The correlation of our design: variables correlated by blocs of 3\n",
    "    corr = np.zeros((n_features, n_features))\n",
    "    for i in range(0, n_features, block_size):\n",
    "        corr[i:i + block_size, i:i + block_size] = 1 - conditioning\n",
    "    corr.flat[::n_features + 1] = 1\n",
    "    corr = linalg.cholesky(corr)\n",
    "\n",
    "    # Our design\n",
    "    X = rng.normal(size=(n_samples, n_features))\n",
    "    X = np.dot(X, corr)\n",
    "    # Keep [Wainwright2006] (26c) constant\n",
    "    X[:n_relevant_features] /= np.abs(\n",
    "        linalg.svdvals(X[:n_relevant_features])).max()\n",
    "    X = StandardScaler().fit_transform(X.copy())\n",
    "\n",
    "    # The output variable\n",
    "    y = np.dot(X, coef)\n",
    "    y /= np.std(y)\n",
    "    # We scale the added noise as a function of the average correlation\n",
    "    # between the design and the output variable\n",
    "    y += noise_level * rng.normal(size=n_samples)\n",
    "    mi = mutual_incoherence(X[:, :n_relevant_features],\n",
    "                            X[:, n_relevant_features:])\n",
    "\n",
    "    data.append([[], []])\n",
    "    # Plot stability selection path, using a high eps for early stopping\n",
    "    # of the path, to save computation time\n",
    "    alpha_grid, scores_path = lasso_stability_path(X, y, random_state=42,\n",
    "                                                   eps=0.05)\n",
    "\n",
    "    \n",
    "    # We plot the path as a function of alpha/alpha_max to the power 1/3: the\n",
    "    # power 1/3 scales the path less brutally than the log, and enables to\n",
    "    # see the progression along the path\n",
    "    \n",
    "    y_ = data_to_plotly(scores_path[coef != 0].T[1:])\n",
    "    \n",
    "    for l in range(0, len(y_)):\n",
    "        if(l==1):\n",
    "            leg=True\n",
    "        else:\n",
    "            leg=False\n",
    "            \n",
    "        hg = go.Scatter(x=alpha_grid[1:] ** .333, \n",
    "                        y=y_[l],\n",
    "                        mode='lines', \n",
    "                        showlegend=leg,\n",
    "                        line=dict(color='red', width=1),\n",
    "                        name='relevant features')\n",
    "        data[k][0].append(hg)\n",
    "        \n",
    "    y_ = data_to_plotly(scores_path[coef == 0].T[1:])\n",
    "    \n",
    "    for l in range(0, len(y_)):\n",
    "        if(l==1):\n",
    "            leg=True\n",
    "        else:\n",
    "            leg=False\n",
    "            \n",
    "        hb = go.Scatter(x=alpha_grid[1:] ** .333, \n",
    "                        y=y_[l],\n",
    "                        mode='lines', \n",
    "                        showlegend=leg,\n",
    "                        line=dict(color='black', width=1),\n",
    "                        name='irrelevant features' \n",
    "                       )\n",
    "        data[k][0].append(hb)\n",
    "    \n",
    "    titles.append('Stability Scores Path<br>Mutual incoherence: %.1f' % mi)\n",
    "    \n",
    "    \n",
    "    # Plot the estimated stability scores for a given alpha\n",
    "\n",
    "    # Use 6-fold cross-validation rather than the default 3-fold: it leads to\n",
    "    # a better choice of alpha:\n",
    "    # Stop the user warnings outputs- they are not necessary for the example\n",
    "    # as it is specifically set up to be challenging.\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', UserWarning)\n",
    "        warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "        lars_cv = LassoLarsCV(cv=6).fit(X, y)\n",
    "\n",
    "    # Run the RandomizedLasso: we use a paths going down to .1*alpha_max\n",
    "    # to avoid exploring the regime in which very noisy variables enter\n",
    "    # the model\n",
    "    alphas = np.linspace(lars_cv.alphas_[0], .1 * lars_cv.alphas_[0], 6)\n",
    "    clf = RandomizedLasso(alpha=alphas, random_state=42).fit(X, y)\n",
    "    trees = ExtraTreesRegressor(100).fit(X, y)\n",
    "    # Compare with F-score\n",
    "    F, _ = f_regression(X, y)\n",
    "\n",
    "    \n",
    "    for name, score in [('F-test', F),\n",
    "                        ('Stability selection', clf.scores_),\n",
    "                        ('Lasso coefs', np.abs(lars_cv.coef_)),\n",
    "                        ('Trees', trees.feature_importances_),\n",
    "                        ]:\n",
    "        precision, recall, thresholds = precision_recall_curve(coef != 0,\n",
    "                                                               score)\n",
    "        p1 = go.Scatter(y=np.maximum(score / np.max(score), 1e-4),\n",
    "                        mode='lines',\n",
    "                        line=dict(width=1),\n",
    "                        name=\"%s. AUC: %.3f\" % (name, auc(recall, precision)))\n",
    "        data[k][1].append(p1)\n",
    "\n",
    "    p2 = go.Scatter(x=np.where(coef != 0)[0], y=[2e-4] * n_relevant_features,\n",
    "                    mode='markers',\n",
    "                    marker=dict(color='magenta'),\n",
    "                    name=\"Ground truth\")\n",
    "    data[k][1].append(p2)\n",
    "    \n",
    "    titles.append('Feature selection scores<br>Mutual incoherence: %.1f'\n",
    "                    % mi)\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = tools.make_subplots(rows=1, cols=2, \n",
    "                          subplot_titles=tuple(titles[:2]))\n",
    "\n",
    "for j in range(0, len(data[0][0])):\n",
    "    fig.append_trace(data[0][0][j], 1, 1)\n",
    "    \n",
    "for m in range(0, len(data[0][1])):\n",
    "    fig.append_trace(data[0][1][m], 1, 2)\n",
    "\n",
    "fig['layout']['xaxis1'].update(title='(a/a<sub>max</sub>)^^1/3')\n",
    "fig['layout']['xaxis2'].update(title='Features', range=[0, 100])\n",
    "\n",
    "fig['layout']['yaxis1'].update(title='Stability score: proportion of times selected')\n",
    "fig['layout']['yaxis2'].update(title='Score', type='log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The draw time for this plot will be slow for clients without much RAM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diksha/anaconda2/lib/python2.7/site-packages/plotly/plotly/plotly.py:1450: UserWarning:\n",
      "\n",
      "Estimated Draw Time Slow\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Diksha_Gabha/3301.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = tools.make_subplots(rows=1, cols=2, \n",
    "                          subplot_titles=tuple(titles[2:4]))\n",
    "\n",
    "for j in range(0, len(data[1][0])):\n",
    "    fig.append_trace(data[0][0][j], 1, 1)\n",
    "    \n",
    "for m in range(0, len(data[1][1])):\n",
    "    fig.append_trace(data[0][1][m], 1, 2)\n",
    "\n",
    "fig['layout']['xaxis1'].update(title='(a/a<sub>max</sub>)^^1/3')\n",
    "fig['layout']['xaxis2'].update(title='Features', range=[0, 100])\n",
    "\n",
    "fig['layout']['yaxis1'].update(title='Stability score: proportion of times selected')\n",
    "fig['layout']['yaxis2'].update(title='Score', type='log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The draw time for this plot will be slow for clients without much RAM.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Diksha_Gabha/3303.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: \n",
    "\n",
    "        Alexandre Gramfort and Gael Varoquaux\n",
    "\n",
    "License:\n",
    "\n",
    "        BSD 3 clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href=\"//fonts.googleapis.com/css?family=Open+Sans:600,400,300,200|Inconsolata|Ubuntu+Mono:400,700\" rel=\"stylesheet\" type=\"text/css\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"http://help.plot.ly/documentation/all_static/css/ipython-notebook-custom.css\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/plotly/publisher.git\n",
      "  Cloning https://github.com/plotly/publisher.git to /tmp/pip-pwiAGU-build\n",
      "Installing collected packages: publisher\n",
      "  Found existing installation: publisher 0.10\n",
      "    Uninstalling publisher-0.10:\n",
      "      Successfully uninstalled publisher-0.10\n",
      "  Running setup.py install for publisher ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25hSuccessfully installed publisher-0.10\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML('<link href=\"//fonts.googleapis.com/css?family=Open+Sans:600,400,300,200|Inconsolata|Ubuntu+Mono:400,700\" rel=\"stylesheet\" type=\"text/css\" />'))\n",
    "display(HTML('<link rel=\"stylesheet\" type=\"text/css\" href=\"http://help.plot.ly/documentation/all_static/css/ipython-notebook-custom.css\">'))\n",
    "\n",
    "! pip install git+https://github.com/plotly/publisher.git --upgrade\n",
    "import publisher\n",
    "publisher.publish(\n",
    "    'Sparse Recovery Feature Selection for Sparse Linear Models.ipynb', 'scikit-learn/plot-sparse-recovery/', 'Sparse Recovery Feature Selection for Sparse Linear Models | plotly',\n",
    "    ' ',\n",
    "    title = 'Sparse Recovery Feature Selection for Sparse Linear Models | plotly',\n",
    "    name = 'Sparse Recovery Feature Selection for Sparse Linear Models',\n",
    "    has_thumbnail='true', thumbnail='thumbnail/sparse-recovery.jpg', \n",
    "    language='scikit-learn', page_type='example_index',\n",
    "    display_as='linear_models', order=30,\n",
    "    ipynb= '~Diksha_Gabha/3305')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
