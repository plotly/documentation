{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example illustrates the effect of the parameters gamma and C of the Radial Basis Function (RBF) kernel SVM.\n",
    "\n",
    "Intuitively, the gamma parameter defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’. The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors.\n",
    "The C parameter trades off misclassification of training examples against simplicity of the decision surface. A low C makes the decision surface smooth, while a high C aims at classifying all training examples correctly by giving the model freedom to select more samples as support vectors.\n",
    "\n",
    "The first plot is a visualization of the decision function for a variety of parameter values on a simplified classification problem involving only 2 input features and 2 possible target classes (binary classification). Note that this kind of plot is not possible to do for problems with more features or target classes.\n",
    "The second plot is a heatmap of the classifier’s cross-validation accuracy as a function of C and gamma. For this example we explore a relatively large grid for illustration purposes. In practice, a logarithmic grid from 10^{-3} to 10^3 is usually sufficient. If the best parameters lie on the boundaries of the grid, it can be extended in that direction in a subsequent search.\n",
    "\n",
    "Note that the heat map plot has a special colorbar with a midpoint value close to the score values of the best performing models so as to make it easy to tell them appart in the blink of an eye.\n",
    "The behavior of the model is very sensitive to the gamma parameter. If gamma is too large, the radius of the area of influence of the support vectors only includes the support vector itself and no amount of regularization with C will be able to prevent overfitting.\n",
    "\n",
    "When gamma is very small, the model is too constrained and cannot capture the complexity or “shape” of the data. The region of influence of any selected support vector would include the whole training set. The resulting model will behave similarly to a linear model with a set of hyperplanes that separate the centers of high density of any pair of two classes.\n",
    "\n",
    "For intermediate values, we can see on the second plot that good models can be found on a diagonal of C and gamma. Smooth models (lower gamma values) can be made more complex by selecting a larger number of support vectors (larger C values) hence the diagonal of good performing models.\n",
    "\n",
    "Finally one can also observe that for some intermediate values of gamma we get equally performing models when C becomes very large: it is not necessary to regularize by limiting the number of support vectors. The radius of the RBF kernel alone acts as a good structural regularizer. In practice though it might still be interesting to limit the number of support vectors with a lower value of C so as to favor models that use less memory and that are faster to predict.\n",
    "\n",
    "We should also note that small differences in scores results from the random splits of the cross-validation procedure. Those spurious variations can be smoothed out by increasing the number of CV iterations n_splits at the expense of compute time. Increasing the value number of C_range and gamma_range steps will increase the resolution of the hyper-parameter heat map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New to Plotly?\n",
    "Plotly's Python library is free and open source! [Get started](https://plot.ly/python/getting-started/) by downloading the client and [reading the primer](https://plot.ly/python/getting-started/).\n",
    "<br>You can set up Plotly to work in [online](https://plot.ly/python/getting-started/#initialization-for-online-plotting) or [offline](https://plot.ly/python/getting-started/#initialization-for-offline-plotting) mode, or in [jupyter notebooks](https://plot.ly/python/getting-started/#start-plotting-online).\n",
    "<br>We also have a quick-reference [cheatsheet](https://images.plot.ly/plotly-documentation/images/python_cheat_sheet.pdf) (new!) to help you get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial imports [SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC), [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler), [load_iris](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris), [StratifiedShuffleSplit](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit) and [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utility function to move the midpoint of a colormap to be around\n",
    "# the values of interest.\n",
    "\n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare data set\n",
    "\n",
    "Dataset for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dataset for decision function visualization: we only keep the first two\n",
    "# features in X and sub-sample the dataset to keep only 2 classes and\n",
    "# make it a binary classification problem.\n",
    "\n",
    "X_2d = X[:, :2]\n",
    "X_2d = X_2d[y > 0]\n",
    "y_2d = y[y > 0]\n",
    "y_2d -= 1\n",
    "\n",
    "# It is usually a good idea to scale the data for SVM training.\n",
    "# We are cheating a bit in this example in scaling all of the data,\n",
    "# instead of fitting the transformation on the training set and\n",
    "# just applying it on the test set.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_2d = scaler.fit_transform(X_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifiers\n",
    "\n",
    "For an initial search, a logarithmic grid with basis 10 is often helpful. Using a basis of 2, a finer tuning can be achieved but at a much higher cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 1.0, 'gamma': 0.10000000000000001} with a score of 0.97\n"
     ]
    }
   ],
   "source": [
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "# Now we need to fit a classifier for all parameters in the 2d version\n",
    "# (we use a smaller set of parameters here because it takes a while to train)\n",
    "\n",
    "C_2d_range = [1e-2, 1, 1e2]\n",
    "gamma_2d_range = [1e-1, 1, 1e1]\n",
    "classifiers = []\n",
    "for C in C_2d_range:\n",
    "    for gamma in gamma_2d_range:\n",
    "        clf = SVC(C=C, gamma=gamma)\n",
    "        clf.fit(X_2d, y_2d)\n",
    "        classifiers.append((C, gamma, clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw visualization of parameter effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matplotlib_to_plotly(cmap, pl_entries):\n",
    "    h = 1.0/(pl_entries-1)\n",
    "    pl_colorscale = []\n",
    "    \n",
    "    for k in range(pl_entries):\n",
    "        C = map(np.uint8, np.array(cmap(k*h)[:3])*255)\n",
    "        pl_colorscale.append([k*h, 'rgb'+str((C[0], C[1], C[2]))])\n",
    "        \n",
    "    return pl_colorscale\n",
    "\n",
    "cmap = matplotlib_to_plotly(plt.cm.RdBu_r, 5)\n",
    "data = []\n",
    "titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_ = np.linspace(-3, 3, 200)\n",
    "y_ = np.linspace(-3, 3, 200)\n",
    "xx, yy = np.meshgrid(x_, y_)\n",
    "\n",
    "for (k, (C, gamma, clf)) in enumerate(classifiers):\n",
    "    # evaluate decision function in a grid\n",
    "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    data.append([])\n",
    "    titles.append(\"gamma=10^%d, C=10^%d\" % (np.log10(gamma), np.log10(C)))\n",
    "\n",
    "    # visualize parameter's effect on decision function\n",
    "    trace =  go.Heatmap(x=x_, y=y_, z=-Z,\n",
    "                        colorscale=cmap,\n",
    "                        showscale=False)\n",
    "    data[k].append(trace)\n",
    "    trace1 = go.Scatter(x=X_2d[:, 0], y=X_2d[:, 1],\n",
    "                        mode='markers',\n",
    "                        marker=dict(color=y_2d,\n",
    "                                    colorscale=cmap,\n",
    "                                    line=dict(color='black', width=1))\n",
    "                       )\n",
    "    data[k].append(trace1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]  [ (1,3) x3,y3 ]\n",
      "[ (2,1) x4,y4 ]  [ (2,2) x5,y5 ]  [ (2,3) x6,y6 ]\n",
      "[ (3,1) x7,y7 ]  [ (3,2) x8,y8 ]  [ (3,3) x9,y9 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = tools.make_subplots(rows=3, cols=3,\n",
    "                          subplot_titles=tuple(titles))\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    for j in range(0, len(data[i])):\n",
    "        fig.append_trace(data[i][j], i/3+1, i%3+1)\n",
    "        \n",
    "for i in map(str,range(1, 10)):\n",
    "        y = 'yaxis' + i\n",
    "        x = 'xaxis' + i\n",
    "        fig['layout'][y].update(showticklabels=False, ticks='')\n",
    "        fig['layout'][x].update(showticklabels=False, ticks='')\n",
    "        \n",
    "fig['layout'].update(height=700, showlegend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The draw time for this plot will be slow for clients without much RAM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diksha/anaconda2/lib/python2.7/site-packages/plotly/api/v1/clientresp.py:40: UserWarning:\n",
      "\n",
      "Estimated Draw Time Slow\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Diksha_Gabha/3591.embed\" height=\"700px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Draw heatmap of the validation accuracy as a function of gamma and C\n",
    "\n",
    "The score are encoded as colors with the hot colormap which varies from dark red to bright yellow. As the most interesting scores are all located in the 0.92 to 0.97 range we use a custom normalizer to set the mid-point to 0.92 so as to make it easier to visualize the small variations of score values in the interesting range while not brutally collapsing all the low score values to the same color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = grid.cv_results_['mean_test_score'].reshape(len(C_range),\n",
    "                                                     len(gamma_range))\n",
    "trace = go.Heatmap(z=scores, \n",
    "                   colorscale='Hot')\n",
    "\n",
    "layout = go.Layout(title='Validation accuracy',\n",
    "                   xaxis=dict(title='gamma', range=[0, 11]),\n",
    "                   yaxis=dict(title='C', autorange='reversed'))\n",
    "fig = go.Figure(data=[trace], layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Diksha_Gabha/3593.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href=\"//fonts.googleapis.com/css?family=Open+Sans:600,400,300,200|Inconsolata|Ubuntu+Mono:400,700\" rel=\"stylesheet\" type=\"text/css\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"http://help.plot.ly/documentation/all_static/css/ipython-notebook-custom.css\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/plotly/publisher.git\n",
      "  Cloning https://github.com/plotly/publisher.git to /tmp/pip-br82tH-build\n",
      "Installing collected packages: publisher\n",
      "  Found existing installation: publisher 0.10\n",
      "    Uninstalling publisher-0.10:\n",
      "      Successfully uninstalled publisher-0.10\n",
      "  Running setup.py install for publisher ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25hSuccessfully installed publisher-0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diksha/anaconda2/lib/python2.7/site-packages/IPython/nbconvert.py:13: ShimWarning:\n",
      "\n",
      "The `IPython.nbconvert` package has been deprecated. You should import from nbconvert instead.\n",
      "\n",
      "/home/diksha/anaconda2/lib/python2.7/site-packages/publisher/publisher.py:53: UserWarning:\n",
      "\n",
      "Did you \"Save\" this notebook before running this command? Remember to save, always save.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML('<link href=\"//fonts.googleapis.com/css?family=Open+Sans:600,400,300,200|Inconsolata|Ubuntu+Mono:400,700\" rel=\"stylesheet\" type=\"text/css\" />'))\n",
    "display(HTML('<link rel=\"stylesheet\" type=\"text/css\" href=\"http://help.plot.ly/documentation/all_static/css/ipython-notebook-custom.css\">'))\n",
    "\n",
    "! pip install git+https://github.com/plotly/publisher.git --upgrade\n",
    "import publisher\n",
    "publisher.publish(\n",
    "    'RBF SVM Parameters.ipynb', 'scikit-learn/plot-rbf-parameters/', 'RBF SVM Parameters | plotly',\n",
    "    ' ',\n",
    "    title = 'RBF SVM Parameters | plotly',\n",
    "    name = 'RBF SVM Parameters',\n",
    "    has_thumbnail='true', thumbnail='thumbnail/svm-rbf.jpg', \n",
    "    language='scikit-learn', page_type='example_index',\n",
    "    display_as='vector_machines', order=12,\n",
    "    ipynb= '~Diksha_Gabha/3595')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
